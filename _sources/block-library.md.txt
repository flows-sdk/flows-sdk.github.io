# Block Library

A library of Blocks that are part of the Hyperscience platform.


## IDP_SYNC

name: IDP-over-SDM interface block

uuid: 4f911733-6df9-4eaa-833c-81123a9b2040

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| api_domain | string |  | API Domain | The Entity-domain|
| api_method | string |  | API Method | The method to call, within the API domain|
| api_payload | object | {} | API Payload | The payload to pass to the API method|



## WAIT

name: Wait

uuid: da8ee001-d5f7-430a-a4ba-7f2bdeba78b8



## TERMINATE

name: Terminate

uuid: 0f8da001-d341-43ef-b5a9-de6cd4b5354e

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| status | string |  | Termination Status | Terminates the Flow if reached. Will be considered as a successful or failed run depending on the Termination Status|
| output | string | null | Workflow output | The workflow output to be set upon termination|



## MQ_LISTENER

name: Message Queue Listener

uuid: 7e0fcbbe-b6a1-4266-beac-c8034cb2bcb5

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| MQ_TYPE | string | ACTIVE_MQ | Message Queue type | N/A|
| MQ_NO_AUTH_REQUIRED | boolean | False | No auth credentials required | N/A|
| MQ_USERNAME | string | null | Username | N/A|
| MQ_PASSWORD | Password | null | Password | N/A|
| MQ_QUEUE_NAME | string | null | Queue Name | N/A|
| MQ_HOST | string | null | Host Name | N/A|
| MQ_REGION | string | null | AWS Region | N/A|
| MQ_QUEUE_URL | string | null | Queue URL | N/A|
| MQ_USE_EC2_INSTANCE_CREDENTIALS | boolean | True | Use AWS EC2 Instance IAM Role Credentials | If selected, credentials are obtained from the EC2 instance directly, and the AWS Access Key ID and Secret Key are not used.|
| MQ_PORT | integer | N/A | Port Number | N/A|
| MQ_QUEUE_MANAGER | string | null | Queue Manager | N/A|
| MQ_CHANNEL | string | null | Channel | N/A|
| MQ_SSL_CIPHER_SUITE | string | null | SSL cipher suite | SSL cipher suite to use if SSL connection is used|
| MQ_VIRTUAL_HOST | string | null | Virtual Host | N/A|
| MQ_EXCHANGE | string |  | Exchange | N/A|
| MQ_ROUTING_KEY | string | null | Routing key | N/A|
| api_params | object | {} | API Parameters | N/A|



## NORMALIZER

name: Normalizer

uuid: b6ffc60e-6571-43ee-bea8-e9998ea1da25

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| language | string |  | Language | Language used for transcribing fields|
| field_data_types | object | {} | Field Data Types | Field Data Types|
| entries | array | [] | Entries | Entries to normalize|



## FOLDER_TRIGGER

name: Folder Listener

uuid: 51b6ddee-3b57-4deb-a7b3-f4d102561635

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| folder | Path | N/A | Folder to scan for submissions | N/A|
| file_extensions | string | N/A | File extensions | List of file extensions to monitor for (e.g.: 'png, jpg, pdf')|
| has_meta | boolean | False | Enable metadata | Select this if a metadata file is to be expected along with document files (in XXX_index.txt file)|
| poll_interval | integer | 10 | Poll interval | Poll interval in seconds|
| warmup_interval | integer | 15 | Warm-up interval | Seconds to wait past document last modified time before processing it|
| folder_cleanup_delay | integer | 86400 | Folder cleanup delay | Seconds to wait before cleaning up subfolders|
| api_params | object | {} | API Parameters | N/A|



## DISTRIBUTE_TO_STRUCTURED_DOCUMENTS

name: Distribute to Structured Documents

uuid: 055f7f4c-5408-4f71-9d8c-895bec100d32

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| layout_release_uuid | string |  | Layout release UUID | The UUID of the layout release to match against|
| min_confidence | number | 0.1 | Minimum VPC Confidence | Min VPC confidence to consider|
| images | array | [] | List of layout candidates |  A list of layout uuids and corresponding confidence for each image|



## CUSTOM_CODE

name: CustomCode

uuid: 4d61afaf-1638-489b-b131-e75c7bfebc7d

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| code | MultilineText |  | Code | Code to be executed|
| timeout | integer | 900 | Timeout | Number of seconds the code is allowed to run before we consider it timed out.|
| data | object | null | Data | A key-value mapping passed directly into the input code|
| script_ref | File | null | Script | Reference to a .py file to be executed with preference over the contents of 'code'|



## HTTP_EXPORT

name: HTTP Notifier

uuid: 4a57864c-f9cd-11ea-adc1-0242ac120002

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| endpoint | string | N/A | Endpoint URL | URL that output notifications will be posted to|
| authorization_type | string | none | Authorization type | Type of authorization|
| authorization_header | Password | null | Authorization header | Authorization header to be set in the notification request|
| auth_url | string | null | OAuth2 authorization URL | The endpoint for the authorization server|
| client_id | string | null | Client ID | The client identifier issued to the client during the application registration process|
| client_secret | Password | null | Client Secret | The client secret issued to the client during the application registration process|
| audience | string | null | Audience | Resource service URL where token will be valid|
| payload_uuid | string | null | Payload UUID | Payload to be sent in notification|



## PRIMITIVE_LIBRARY_CODE

name: Primitive Library Code

uuid: b3d101de-4c9a-4637-8256-a962362bd227

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| code | MultilineText |  | Code | Code to be executed|
| timeout | integer | 900 | Timeout | Number of seconds the code is allowed to run before we consider it timed out.|
| data | object | null | Data | A key-value mapping passed directly into the input code|



## FINETUNE

name: Finetune

uuid: 56e4fe16-5e99-4337-ab21-bca9259b2622

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| model_id | string |  | Model identifier | Identifier used for downloading the finetuning model|
| model_info_url | string |  | ML Model Info URL | URL to use for ML model info retrieval|
| model_info_params | object |  | ML Model Info Params | Parameters to be passed along with the ML Model Info URL|
| model_type | string |  | Model type | The finetuning model type|
| fields | array | [] | Fields | Fields|
| field_data_type_map | object | {} | Field Data Type Map | Field data types mapped by UUID|
| image_uuid | string |  | Image UUID | Image UUID|
| layout_image_uuid | string |  | Layout Image UUID | Layout Image UUID|



## HV_PAYLOAD_GENERATOR

name: Hyperversary Payload Generator

uuid: 1693d57d-8231-4298-a3e9-cd7cd51837f4

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| $alias_name | string | CUSTOM_CODE | Aliased Block | Aliased Block|
| $partial_input_parameters | object | {'code': "from datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom pydantic import BaseModel, Field\n\nfrom blocks.base_python_block import Block, WFEngineTask, WFEngineTaskResult\nfrom blocks.types import BlockInputs\n\n\nclass ICalReaderEvent(BaseModel):\n    start: datetime\n    end: Optional[datetime] = None\n    summary: str\n    organizer: Optional[str] = None\n    attendees: Optional[List[str]] = Field(default_factory=list)\n\n\nclass CalendarInput(BaseModel):\n    events: List[ICalReaderEvent]\n\n\nclass CustomCodeBlockProxyInputs(BlockInputs):\n    anniversary_events: CalendarInput\n    birthday_events: CalendarInput\n    exclude_birthdays: List[str]\n\n\ndef _get_markdown_row(plain_text: str) -> Dict[str, Any]:\n    return {'type': 'section', 'text': {'type': 'mrkdwn', 'text': plain_text}}\n\n\ndef _is_birthday_event(summary: str, exclude_bdays: List[str]) -> bool:\n    return 'Birthday' in summary and not any(member in summary for member in exclude_bdays)\n\n\ndef _is_anniversary_event(summary: str) -> bool:\n    return 'anniversary' in summary\n\n\ndef process_task(\n    proxy: Block, task: WFEngineTask[CustomCodeBlockProxyInputs]\n) -> WFEngineTaskResult:\n    # Load inputs\n    anniversary_events: List[ICalReaderEvent] = task.inputData.anniversary_events.events\n    birthday_events: List[ICalReaderEvent] = task.inputData.birthday_events.events\n    exclude_bdays: List[str] = task.inputData.exclude_birthdays\n\n    blocks = []\n    for event in anniversary_events:\n        summary = event.summary\n        blocks.append(_get_markdown_row(f':tada: Hyperversary {summary}!! :tada:'))\n    for event in birthday_events:\n        summary = event.summary\n        if _is_birthday_event(summary, exclude_bdays):\n            summary = 'Happy Birthday, ' + summary.replace(' - Birthday', '!!')\n            blocks.append(_get_markdown_row(f':birthday: {summary} :birthday:'))\n\n    if blocks:\n        header = [_get_markdown_row('List of events for today:')]\n        return {'blocks': header + blocks}\n\n    return {}\n"} | Partial Input Parameters | Pass these partial input parameters to the aliased block|
| anniversary_events | object | [] | Anniversary events | A list of anniversary event strings|
| birthday_events | object | [] | Birthday events | A list of birthday event strings|
| exclude_birthdays | array | [] | Excluded birthdays | Birthday notifications blacklist|



## KOFAX_FOLDER_TRIGGER

name: Kofax Folder Listener

uuid: 06dd55c7-0124-4403-9b8d-04b57e8afca2

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| folder | Path | N/A | Folder to scan for submissions | N/A|
| file_extensions | string | N/A | File extensions | List of file extensions to monitor for (e.g.: 'png, jpg, pdf')|
| poll_interval | integer | 10 | Poll interval in seconds | N/A|
| warmup_interval | integer | 15 | Warm-up interval | Seconds to wait past document last modified time before processing it|
| folder_cleanup_delay | integer | 86400 | Folder cleanup delay | Seconds to wait before cleaning up subfolders|
| api_params | object | {} | API Parameters | N/A|



## EXPORT_EMAIL

name: Email Notifier

uuid: d48463e0-32ee-43dc-a8a8-48d1b2ff3b87

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| from_email | string | N/A | From | Name<email> of the sender|
| to_emails | string | N/A | To | Comma-separated list of email addresses|
| cc_emails | string | null | CC | Comma-separated list of email addresses|
| subject | string | null | Subject | Subject of email|
| smtp_host | string | N/A | SMTP Host | Host name or IP of the SMTP server|
| smtp_port | integer | 587 | SMTP Port | SMTP server's listening port|
| smtp_username | string | N/A | SMTP Username | Username for the SMTP server|
| smtp_password | Password | N/A | SMTP Password | Password for the SMTP server|
| mako_template | MultilineText | null | Mako Template | Mako template to convert submissions's payload|
| file_uuid_list | array | [] | File UUIDs | List of file uuids|
| payload_uuid | string | null | Payload | Payload to be sent in notification|



## ICAL_READER

name: ICal Reader

uuid: 3bbcf5ed-c0a4-4195-8738-c0823e44af6c

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| calendar_url | string | N/A | ICalendar URL | N/A|
| start | DateTime | null | Start time | Lower limit of the interval by which the calendar events are selected, inclusive. Should not include time zone info. If null is provided a default value of TODAY 00:01 is used|
| end | DateTime | null | End time | Upper limit of the interval by which the calendar events are selected, inclusive. Should not include time zone info. If null is provided a default value of TODAY 23:59 is used|



## OCS_DOWNLOADER

name: OCS Downloader

uuid: b1142dfa-7636-4700-a4c4-ef5d9805945f

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| config | json | N/A |  | N/A|
| url | string |  | OCS URL | OCS URL|



## DB_ACCESS

name: Database Request

uuid: 3d2c7993-3096-4d83-884d-c447500dc063

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| db_type | string | mssql | Database type | N/A|
| host | string | N/A | Host/Server | URL/IP Address of the server DB is hosted on|
| port | integer | 1433 | Port | N/A|
| database | string | N/A | Database/Service | Database or Service name|
| username | string | N/A | Username | N/A|
| password | string | N/A | Password | N/A|
| options | object | {} | Additional Options | Dictionary of additional connection string options|
| timeout | integer | 120 | Timeout | Timeout in seconds|
| query | MultilineText | N/A | Query | Parameterized query|
| query_params | object | {} | Parameters | Dictionary of values for query placeholders|



## IMAGE_REGISTRATION

name: Image Registration

uuid: 29ae3033-00c4-4a0c-bf0e-21a954dec140

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| $alias_name | string | CUSTOM_CODE | Aliased Block | Aliased Block|
| $partial_input_parameters | object | {'code': 'import gzip\nimport pickle\nfrom http import HTTPStatus\nfrom io import BytesIO\nfrom typing import Any, BinaryIO, Dict, Union\n\nimport numpy as np\n\nfrom blocks.api import BINARY_KV_CREATE_URL, BINARY_KV_DOWNLOAD_URL, IDP_IMAGES_URL\nfrom blocks.base_python_block import BlobCreateParams, Block, WFEngineTask, WFEngineTaskResult\nfrom blocks.types import BlockInputs\nfrom sdm_image.image_registration.registration import RegistrationException, RegistrationManager\nfrom sdm_image.image_utils.image_utils import (\n    IMAGE_UTILS_HEX,\n    encode_image_as_png,\n    grayscale_image_from_buf,\n    registration_images,\n)\n\n\nclass CustomCodeBlockProxyInputs(BlockInputs):\n    image_uuid: str\n    layout_image_uuid: str\n    find_homography_max_iterations: int = 2000\n    find_homography_confidence: float = 0.995\n\n\ndef process_task(\n    proxy: Block, task: WFEngineTask[CustomCodeBlockProxyInputs]\n) -> WFEngineTaskResult:\n    workflow_instance_id = task.workflowInstanceId\n    image_uuid: str = task.inputData.image_uuid\n    layout_image_uuid: str = task.inputData.layout_image_uuid\n\n    proxy.log(\n        \'Received input: image_uuid=`{}`, layout_image_uuid={} for WF={}\',\n        image_uuid,\n        layout_image_uuid,\n        workflow_instance_id,\n    )\n\n    # fetch the image\n    image_blob = proxy.fetch_blob(blobref=image_uuid)\n    original_image, grayscale_image = registration_images(image_blob.content)\n\n    layout_image_result: Dict[str, Any] = {\'layout_image_uuid\': layout_image_uuid}\n\n    regman = RegistrationManager(\n        max_iters=task.inputData.find_homography_max_iterations,\n        confidence=task.inputData.find_homography_confidence,\n    )\n\n    # fetch the precomputed registration data\n    binary_kv_params = {\n        \'tag\': \'REGISTRATION\',\n        \'version\': regman.VERSION,\n        \'code_hash\': IMAGE_UTILS_HEX,\n    }\n    binary_kv_url = BINARY_KV_DOWNLOAD_URL.format(image_uuid=layout_image_uuid)\n    resp = proxy.sdm_get(\n        binary_kv_url, params=binary_kv_params, handled_error_codes=[HTTPStatus.NOT_FOUND.value]\n    )\n    if resp.status_code == HTTPStatus.NOT_FOUND.value:\n        proxy.log(\'Precomputed registration data not available for {}\', layout_image_uuid)\n        layout_image_blob = proxy.sdm_get(IDP_IMAGES_URL.format(image_uuid=layout_image_uuid))\n        grayscale_img = grayscale_image_from_buf(layout_image_blob.content)\n        template = regman.add_template(layout_image_uuid, grayscale_img)\n        # cache on server\n        proxy.sdm_post(\n            BINARY_KV_CREATE_URL,\n            data={\n                \'uuid\': layout_image_uuid,\n                \'tag\': \'REGISTRATION\',\n                \'version\': RegistrationManager.VERSION,\n                \'code_hash\': IMAGE_UTILS_HEX,\n            },\n            files=[(\'data\', gzp_dumpb(template))],\n        )\n    else:\n        precomputed_data = pickle.load(\n            gzip.GzipFile(fileobj=BytesIO(resp.content), mode=\'rb\')  # type: ignore [arg-type]\n        )\n        regman.add_template_precomputed(layout_image_uuid, precomputed_data)\n\n    # perform the registration\n    try:\n        features = regman.find_transform(grayscale_image, layout_image_uuid)\n        precomputed_layout_shape, template_shape = regman.template_shapes[layout_image_uuid]\n        layout_image_result[\'registration_found\'] = True\n        layout_image_result[\'registration_details\'] = {\n            \'total_keypoints\': features[\'possible_matches\'],\n            \'matches\': len(features[\'matches\']),\n            \'inliers\': int(np.sum(features[\'inliers\'])),\n            \'confidence\': float(features[\'confidence\']),\n            \'transformation_matrix\': features[\'xform\'].tolist(),\n            \'preprocessing_method\': features[\'preprocessing_method\'],\n            \'layout_shape\': features[\'template_shapes\'],\n            \'precomputed_shape\': features[\'precomputed_shape\'],\n        }\n\n        warped_image = RegistrationManager.warp_image(\n            original_image,\n            template_shape,\n            features[\'xform\'],\n            precomputed_layout_shape,\n            features[\'precomputed_shape\'],\n        )\n\n        # store the registered image\n        bcp = BlobCreateParams(\n            name=\'registered_{}\'.format(image_uuid), content=encode_image_as_png(warped_image)\n        )\n\n        layout_image_result[\'registered_image_blob\'] = proxy.store_blob(\n            bcp, workflow_run_uuid=task.workflowInstanceId\n        )\n\n    except RegistrationException:  # no registration has been found\n        layout_image_result[\'registration_found\'] = False\n\n    output_data: WFEngineTaskResult = layout_image_result\n    return output_data\n\n\ndef gzp_dumpb(obj: object) -> bytes:\n    """Return a zipped pickle of the object as a bytes"""\n    fileobj = BytesIO()\n    try:\n        gzp_dump(obj, fileobj)\n        fileobj.flush()\n        value = fileobj.getvalue()\n    finally:\n        fileobj.close()\n    return value\n\n\ndef gzp_dump(obj: object, fileobj: Union[str, BinaryIO]) -> None:\n    """Given an object and a filename or file object, dump to latter"""\n    if isinstance(fileobj, str):\n        file = gzip.GzipFile(filename=fileobj, mode=\'wb\')\n    else:\n        file = gzip.GzipFile(mode=\'wb\', fileobj=fileobj)\n    try:\n        # note use of _binary_ pickle format for speed/size\n        pickle.dump(obj, file, 1)  # type: ignore [arg-type]\n    finally:\n        file.close()\n'} | Partial Input Parameters | Pass these partial input parameters to the aliased block|
| image_uuid | string |  | Image UUID | Image UUID string|
| layout_image__uuids | array | [] | Layout Image UUIDs | List of layout image uuids|
| find_homography_max_iterations | integer | 2000 | Find homography max iterations | Max iterations parameter used in find homography|
| find_homography_confidence | number | 0.995 | Find homography confidence | Confidence parameter used in find homography|



## FILE_PAGINATION

name: File Pagination

uuid: 5ad268b2-3cde-4947-a463-72d62361de8f

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| $alias_name | string | CUSTOM_CODE | Aliased Block | Aliased Block|
| $partial_input_parameters | object | {'code': "import math\nimport uuid\nfrom typing import List, Optional, Tuple\n\nimport cv2\nimport numpy as np\n\nfrom blocks.base_python_block import (\n    BlobAPIReference,\n    BlobCreateParams,\n    Block,\n    WFEngineTask,\n    WFEngineTaskResult,\n)\nfrom blocks.types import BlockInputs\nfrom sdm_image.image_utils.image_read import (\n    ImageEncryptedException,\n    ImageException,\n    UnsupportedImageMimeType,\n    flatten_zip,\n    parse_uploaded_file_data,\n)\nfrom sdm_image.image_utils.image_utils import decode_image\n\n# Pages with too high resolution are automatically rescaled (preserving the\n# the aspect ratio) to contain MAX_PAGE_PIXELS which is A4 scanned at\n# 300 dpi. Note that Letter < A4\nPREFERRED_DPI = 300\nMAX_PAGE_PIXELS = math.ceil((PREFERRED_DPI * 11.6) * (PREFERRED_DPI * 8.27))\n\n\nclass CustomCodeBlockProxyInputs(BlockInputs):\n    file_uuid: str\n\n\ndef resize_submission_image_if_needed(np_image: np.array) -> Optional[np.array]:\n    w, h = np_image.shape[1], np_image.shape[0]\n    if w * h <= MAX_PAGE_PIXELS:\n        return None\n\n    scale = math.sqrt(MAX_PAGE_PIXELS / (w * h))\n    w = int(w * scale)\n    h = int(h * scale)\n    return cv2.resize(np_image, (w, h), interpolation=cv2.INTER_AREA)\n\n\ndef process_task(\n    proxy: Block, task: WFEngineTask[CustomCodeBlockProxyInputs]\n) -> WFEngineTaskResult:\n    # Load inputs\n    workflow_instance_id = task.workflowInstanceId\n    file_uuid = task.inputData.file_uuid\n\n    proxy.log_dev('Received input: file_uuid=`{}` for WF={}', file_uuid, workflow_instance_id)\n\n    # Fetch input BLOB over the API\n    proxy.log_dev('Loading blob: `{}`', file_uuid)\n    input_blob = proxy.fetch_blob(blobref=file_uuid)\n    blob_metadata = proxy.fetch_blob_metadata(blobref=file_uuid)\n\n    # Run the actual pagination\n    proxy.log_dev('Paginating blob: `{}`', file_uuid)\n\n    storage_results: List[BlobAPIReference] = []\n    flat_data: List[Tuple[bytes, str, Optional[Exception]]] = flatten_zip(input_blob.content)\n    for image_data, image_name, exception in flat_data:\n        image_name = blob_metadata.name + image_name\n\n        # Run the pagination on the unzipped files\n        proxy.log_dev('Paginating blob: `{}`', image_name)\n        try:\n            if exception is not None:\n                raise exception\n\n            pagination_results = parse_uploaded_file_data(data=image_data, file_name=image_name)\n            # Store output BLOBs over the API\n            blobs_to_store = []\n            for r in pagination_results:\n                np_image = decode_image(r.data)\n                resized_np_image = resize_submission_image_if_needed(np_image)\n                blobs_to_store.append(\n                    BlobCreateParams(\n                        name=str(uuid.uuid4()),\n                        url=r.name,\n                        content=r.data\n                        if resized_np_image is None\n                        else bytes(cv2.imencode('.png', resized_np_image)[1]),\n                    )\n                )\n            proxy.log_dev(\n                'Pagination results: \\n {}', '\\n'.join(str(p) for p in pagination_results)\n            )\n\n            file_storage_results: List[BlobAPIReference] = proxy.store_blobs(\n                blobs=blobs_to_store, workflow_run_uuid=workflow_instance_id\n            )\n        except (ImageEncryptedException, UnsupportedImageMimeType, ImageException, cv2.error) as e:\n            proxy.log('Pagination failed: {}', e)\n            result = proxy.store_blob(\n                blob=BlobCreateParams(name=str(uuid.uuid4()), url=image_name, content=image_data),\n                workflow_run_uuid=workflow_instance_id,\n            )\n            result['exception_type'] = (\n                ImageException.__name__ if isinstance(e, cv2.error) else type(e).__name__\n            )\n            file_storage_results = [result]\n\n        # Populate file UUID so that we can keep track of where the image comes from\n        for s in file_storage_results:\n            s['file_uuid'] = file_uuid\n\n        storage_results += file_storage_results\n\n    # Finish task\n    output_data = {'storage_results': storage_results}\n    return output_data\n"} | Partial Input Parameters | Pass these partial input parameters to the aliased block|
| file_uuid | string |  | File UUID | File UUID|



## IMAP_TRIGGER

name: Email Listener (IMAP)

uuid: 67056d96-b485-4005-aab2-c709df60933c

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| host | string | N/A | IMAP server address | N/A|
| port | integer | 993 | Port Number | N/A|
| ssl | boolean | True | Use SSL connection | N/A|
| username | string | N/A | Username | N/A|
| password | Password | N/A | Password | N/A|
| poll_interval | integer | 60 | Polling interval in seconds | N/A|
| folder | Path | N/A | Folder to scan for emails | N/A|
| email_body_treatment | string | ignore | Email body treatment | What to do with the body of an email that is ingested|
| post_process_action | string | move | Post process action | What to do with the email after it is processed|
| post_process_move_folder | string |  | Post process archive folder | Folder to move emails to once they are processed|
| api_params | object | {} | API Parameters | N/A|



## VPC

name: Visual Page Classifier

uuid: fce9f35c-cd90-47cd-9df6-63328d563821

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| layout_release_uuid | string |  | Layout release UUID | The UUID of the layout release to match against|
| vpc_settings | string | null | VPC Settings Preset | The name of the settings preset that VPC should run with. Optional.|
| image_uuid | string |  | Image UUID | Image UUID|
| image_source | string |  | Image source (IDP or empty) | Image source to be used for fetching the image specified by image_uuid|



## EASY_OCR

name: EASY_OCR transcriber

uuid: fd321fa1-bee2-4a5b-8318-1e067218e716

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| fields | array | [] | Fields | Fields|
| image_uuid | string |  | Image UUID | Image UUID|



## IMAGE_CORRECTION

name: Image Correction

uuid: 7289e212-b42c-4d05-aa0d-c9189e24fa65

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| uuid | string |  | Image UUID | Image UUID|
| rotation_correction_enabled | boolean | True | Rotation Correction Enabled on the Input Image | Rotation Correction Enabled on the Input Image|
| mobile_correction_enabled | boolean | True | Perspective Transformation Correction Enabled on the Input Image | Perspective Transformation Correction Enabled on the Input Image|
| mobile_scanned_detection_threshold | float | 0.04 | Threshold Value To Classify Document As Scanned | Threshold Value To Classify Document As Scanned|
| mobile_min_pixel_detection | integer | 25 | Minimum Document Pixels | Minimum Document Pixels|
| image_source | string |  | Image source (IDP or empty) | Image source to be used for fetching the image specified by image_uuid|



## SLACK_NOTIFIER

name: Slack notifier

uuid: 68a45bb5-1dae-413d-a377-d14338639b7d

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| webhook_url | string | N/A | Webhook URL | The webhook URL generated for you slack app|
| payload | json | null | Payload | Payload|



## SDM_DOWNLOADER

name: SDM Downloader

uuid: b81fc18d-086b-436f-9cb4-1ef8dc6af135

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| url | string |  | URL | URL or path within the host application, e.g. sdm://image/xxxxx, or simply /image/xxxxx|



## HTTP_REST

name: HTTP API Request

uuid: 91c4d870-8594-46eb-a0f0-fa4e16dcb428

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| $alias_name | string | CUSTOM_CODE | Aliased Block | Aliased Block|
| $partial_input_parameters | object | {'code': "from typing import Any, Dict, List, Optional, Union\nfrom urllib.parse import urljoin\n\nfrom oauthlib.oauth2 import BackendApplicationClient, MissingTokenError\nfrom pydantic import Field\nfrom requests import Response, Session\nfrom requests_oauthlib import OAuth2Session\n\nfrom blocks.base_python_block import Block, WFEngineTask, WFEngineTaskResult\nfrom blocks.types import BlockInputs\nfrom blocks.utils import response_content\n\n\nclass HTTPError(Exception):\n    def __init__(self, code: int, msg: str, *args: object) -> None:\n        super().__init__(*args)\n        self.code = code\n        self.msg = msg\n\n    def __str__(self) -> str:\n        return 'HTTP Error %s: %s' % (self.code, self.msg)\n\n    def __repr__(self) -> str:\n        return '<HTTPError %s: %r>' % (self.code, self.msg)\n\n\nclass CustomCodeBlockProxyInputs(BlockInputs):\n    method: str\n    headers: Dict[str, str] = Field(default_factory=dict)\n    params: Dict[str, Any] = Field(default_factory=dict)\n    payload: Dict[str, str] = Field(default_factory=dict)\n    json_content: Dict[str, Any] = Field(default_factory=dict, alias='json')\n    sdm_app_endpoint: str = ''\n    endpoint: str = ''\n    authorization_header: Optional[str] = None\n    authorization_type: Optional[str] = None\n    auth_url: Optional[str] = None\n    client_id: Optional[str] = None\n    client_secret: Optional[str] = None\n    audience: Optional[str] = None\n    handled_error_codes: Optional[List[Union[int, str]]] = None\n\n\nclass AuthenticatedSession(OAuth2Session):\n    def __init__(\n        self, client: str, token_url: str, client_secret: str, audience: str, **kwargs: Any\n    ) -> None:\n        self._token_url = token_url\n        self._client_secret = client_secret\n        self._audience = audience\n        self._fetching_token = False\n        super().__init__(client=client, **kwargs)\n        try:\n            self.fetch_token(\n                token_url=self._token_url,\n                client_secret=self._client_secret,\n                audience=self._audience,\n            )\n            print('Token fetched', flush=True)\n        except MissingTokenError as ex:\n            raise HTTPError(code=404, msg=f'{self._token_url} was not found') from ex\n\n    def request(self, method: str, url: str, **kwargs: Any) -> Response:\n        return super().request(method, url, **kwargs)\n\n\ndef _get_session(block_input: CustomCodeBlockProxyInputs) -> Session:\n    if not block_input.authorization_type or block_input.authorization_type == 'none':\n        session = Session()\n    elif block_input.authorization_type == 'http_header':\n        session = Session()\n        if block_input.authorization_header:\n            session.headers.update({'Authorization': block_input.authorization_header})\n    else:\n        assert block_input.authorization_type == 'oauth_2_client_credentials'\n        assert block_input.auth_url\n        assert block_input.client_secret\n        assert block_input.audience\n\n        session = AuthenticatedSession(\n            client=BackendApplicationClient(client_id=block_input.client_id),\n            token_url=block_input.auth_url,\n            client_secret=block_input.client_secret,\n            audience=block_input.audience,\n        )\n\n    return session\n\n\ndef is_code_handled(\n    status_code: int, handled_error_codes: Optional[List[Union[int, str]]] = None\n) -> bool:\n    if not handled_error_codes:\n        return False\n\n    status_code_str = str(status_code)\n    for code in handled_error_codes:\n        pattern_code_str = str(code)\n        if len(status_code_str) == len(pattern_code_str) and all(\n            p.lower() == 'x' or s == p for s, p in zip(status_code_str, pattern_code_str)\n        ):\n            return True\n    return False\n\n\ndef process_task(\n    proxy: Block, task: WFEngineTask[CustomCodeBlockProxyInputs]\n) -> WFEngineTaskResult:\n    method = task.inputData.method\n    headers = task.inputData.headers\n    params = task.inputData.params\n    data = task.inputData.payload\n    json_content = task.inputData.json_content\n    url = task.inputData.endpoint\n    handled_error_codes = task.inputData.handled_error_codes\n\n    if not url:\n        url = urljoin(proxy.sdm_app_url, task.inputData.sdm_app_endpoint)\n        headers['Authorization'] = 'Token {}'.format(proxy.sdm_app_auth_token)\n\n    proxy.log('Received input: method={} endpoint={}', method, url)\n\n    kwargs: Any = {'headers': headers, 'params': params}\n    if data:\n        kwargs['data'] = data\n    if json_content:\n        kwargs['json'] = json_content\n\n    with _get_session(task.inputData) as session:\n        response = session.request(method, url, **kwargs)\n\n    if not is_code_handled(response.status_code, handled_error_codes):\n        response.raise_for_status()\n\n    return {\n        'data': response_content(response),\n        'status': response.status_code,\n        'headers': dict(response.headers),\n    }\n"} | Partial Input Parameters | Pass these partial input parameters to the aliased block|
| endpoint | string | null | Endpoint URL | Absolute URL including schema to HTTP endpoint for this request. Mutually exclusive with sdm_app_endpoint.|
| method | string |  | Method | HTTP Method|
| headers | object | {} | HTTP Headers | HTTP Headers|
| authorization_type | string | none | Authorization type | Type of authorization|
| authorization_header | Password | N/A | Authorization header | Authorization header to be set in the notification request|
| auth_url | string | null | OAuth2 authorization URL | The endpoint for the authorization server|
| client_id | string | null | Client ID | The client identifier issued to the client during the application registration process|
| client_secret | Password | N/A | Client Secret | The client secret issued to the client during the application registration process|
| audience | string | null | Audience | Resource service URL where token will be valid|
| sdm_app_endpoint | string | null | HTTP SDM relative URL | Relative URL to a URL served by SDM. Mutually exclusive with endpoint.|
| params | object | null | HTTP Query Params | Key-value pair used as query parameters in the request|
| payload | object | null | HTTP Post urlencoded data | Key-value pair to be used as x-www-form-urlencoded data. Mutually exclusive with json.|
| json | object | null | HTTP Post json-encoded data | Key-value pair to be used as json data. Mutually exclusive with payload.|
| handled_error_codes | array | [] | Handled HTTP error codes | These HTTP error codes will not fail the task. An array with integer and string codes, allowing for wildcards with the `x` char. Example: [400, "5xx"]|



## S3_DOWNLOADER

name: S3 Downloader

uuid: ed85bc11-eee0-4159-b66e-a3e67d5ef4a3

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| config | json | N/A |  | N/A|
| url | string |  | URL | URL|
| endpoint_url | string | null | Endpoint URL | Endpoint URL|



## DISTRIBUTE_TO_STRUCTURED_DOCUMENTS_2

name: Distribute to Structured Documents

uuid: 8d4b2a5d-e5e8-43d6-8300-ad401ea578ef

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| layout_release_uuid | string |  | Layout release UUID | The UUID of the layout release to match against|
| min_confidence | number | 0.1 | Minimum VPC Confidence | Min VPC confidence to consider|
| images | array | [] | List of layout candidates |  A list of layout uuids and corresponding confidence for each image|



## LAMBDA_PYTHON

name: Python Lambda

uuid: 838583a4-da85-4cf3-88af-35133006a827

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| input | object | null | Input for lambda | Input for lambda|
| expression | string |  | A Python lambda expression | A Python lambda expression|



## BOOST_CONFIDENCE

name: Boost Transcription Confidence

uuid: 8c6cf314-e37b-4a89-b7ff-67e322f6b55d

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| $alias_name | string | CUSTOM_CODE | Aliased Block | Aliased Block|
| $partial_input_parameters | object | {'code': "from math import log10\nfrom typing import List, Optional, cast\n\nfrom pydantic import Field as PyField\n\nfrom blocks.base_python_block import Block, WFEngineTask, WFEngineTaskResult\nfrom blocks.types import BaseModel, BlockInputs\n\nCONFIDENCE_BOOSTING_META_TYPES = {\n    'name',\n    'address',\n    'freeform',\n    'email_address',\n    'freeform_nolm',\n    'phone_number',\n    'alphanumeric',\n    'freeform_alphanumeric',\n    'custom',\n}\n\nCONFIDENCE_BOOSTING_MIN_LENGTH = 5\nCONFIDENCE_BOOSTING_MAX_LENGTH = 256\n\nCONFIDENCE_BOOSTING_MIN_OCCURRENCES = 10\n\n\nclass TranscriptionOccurrence(BaseModel):\n    source_uuid: str\n    normalized_transcription: Optional[str]\n    count: int\n\n\nclass Field(BaseModel):\n    identifier: str\n    source_uuid: str\n    meta_type: Optional[str]\n    normalized_transcription: Optional[str] = None\n    confidence: Optional[float] = None\n\n\nclass CustomCodeBlockProxyInputs(BlockInputs):\n    fields_: List[Field] = PyField(alias='fields')\n    transcription_occurrences: List[TranscriptionOccurrence]\n\n\ndef _should_boost_confidence(field: Field) -> bool:\n    confidence_is_valid = field.confidence is not None and 0 <= field.confidence <= 1\n    transcription_is_valid = (\n        field.normalized_transcription is not None\n        and CONFIDENCE_BOOSTING_MIN_LENGTH\n        <= len(field.normalized_transcription)\n        <= CONFIDENCE_BOOSTING_MAX_LENGTH\n    )\n    meta_type_is_valid = field.meta_type in CONFIDENCE_BOOSTING_META_TYPES\n\n    return confidence_is_valid and transcription_is_valid and meta_type_is_valid\n\n\ndef process_task(\n    proxy: Block, task: WFEngineTask[CustomCodeBlockProxyInputs]\n) -> WFEngineTaskResult:\n    transcription_occurrences_map = {\n        (to.source_uuid, to.normalized_transcription): to.count\n        for to in task.inputData.transcription_occurrences\n    }\n\n    result = {}\n    for field in task.inputData.fields_:\n        boosted_confidence = field.confidence\n\n        if _should_boost_confidence(field):\n            occurrences = transcription_occurrences_map.get(\n                (field.source_uuid, field.normalized_transcription), 0\n            )\n            if occurrences >= CONFIDENCE_BOOSTING_MIN_OCCURRENCES:\n                power = min(50, len(cast(str, field.normalized_transcription))) * log10(occurrences)\n                boosted_confidence = cast(float, field.confidence) ** (1 / power)\n\n        result[field.identifier] = boosted_confidence\n\n    return {'result': result}\n"} | Partial Input Parameters | Pass these partial input parameters to the aliased block|
| fields | array | [] | Fields | Fields to which confidence boosting will be applied|
| transcription_occurrences | array | [] | Transcription Occurrences | Specifies the number of occurrences of particular transcription for given Field|



## NLC

name: No Layout Classifier

uuid: 4573e5fd-ea03-4219-abe2-5d2e3c1f264c

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| model_id | string |  | Model identifier | Identifier used for downloading the ML model|
| model_info_url | string |  | ML Model Info URL | URL to use for ML model info retrieval|
| target_accuracy | number |  | Target machine accuracy | Target machine accuracy|
| blended_target_accuracy | number |  | Target blended accuracy | Target blended accuracy|
| pages | array | [] | Pages | List of pages|



## MQ_NOTIFIER

name: Message Queue Notifier

uuid: 313ccdae-5ea7-4da6-ba37-e6fc992a72f2

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| MQ_TYPE | string | ACTIVE_MQ | Message Queue type | N/A|
| MQ_NO_AUTH_REQUIRED | boolean | False | No auth credentials required | N/A|
| MQ_USERNAME | string | null | Username | N/A|
| MQ_PASSWORD | Password | null | Password | N/A|
| MQ_QUEUE_NAME | string | null | Queue Name | N/A|
| MQ_HOST | string | null | Host Name | N/A|
| MQ_REGION | string | null | AWS Region | N/A|
| MQ_QUEUE_URL | string | null | Queue URL | N/A|
| MQ_MESSAGE_GROUP_ID | string | null | Group ID for FIFO queues | Group ID for FIFO queues|
| MQ_USE_EC2_INSTANCE_CREDENTIALS | boolean | True | Use AWS EC2 Instance IAM Role Credentials | If selected, credentials are obtained from the EC2 instance directly, and the AWS Access Key ID and Secret Key are not used.|
| MQ_PORT | integer | 1415 | Port Number | N/A|
| MQ_QUEUE_MANAGER | string | null | Queue Manager | N/A|
| MQ_CHANNEL | string | null | Channel | N/A|
| MQ_SSL_CIPHER_SUITE | string | null | SSL cipher suite | SSL cipher suite to use if SSL connection is used|
| MQ_VIRTUAL_HOST | string | null | Virtual Host | N/A|
| MQ_EXCHANGE | string |  | Exchange | N/A|
| MQ_ROUTING_KEY | string | null | Routing key | N/A|
| payload_uuid | string | null | Payload UUID | Payload to be sent in notification|



## SLACK_SV_DECISION

name: Slack Decision Supervision

uuid: ebc84c9f-422c-4ed5-8473-30b282d28598

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| webhook_url | string | N/A | Webhook URL | The webhook URL generated for you slack app|
| external_job_uuid | string | N/A | External Job | The UUID of the Supervision Job|
| message_title | string | N/A | Title | The title of the message|
| message_body | string | N/A | Message | The message body text|
| image_url | string | null | Image | Image to be displayed inline. Optional.|
| choices_payload | array | [] | Choices Payload | An array with the buttons' markdown. Can be empty.|



## FIELD_LOCATOR

name: Field Locator

uuid: 9aa75ddf-846e-4de0-80d7-73c3537ace97

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| ml_model | object | {'model_id': '', 'model_type': ''} | ML model reference | ML Model reference|
| model_info_url | string |  | ML Model Info URL | URL to use for ML model info retrieval|
| target_accuracy | number |  | Target machine accuracy | Target machine accuracy|
| blended_target_accuracy | number |  | Target blended accuracy | Target blended accuracy|
| field_definitions | array | [] | Field definitions | Definitions of the fields that has to be extracted|
| pages | array | [] | Pages | List of pages|



## OICR

name: OICR transcriber

uuid: 6b276646-3755-4181-9ab6-c6c9793cfdb6

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| fields | array | [] | Fields | Fields|
| field_data_types | object | {} | Field Data Types | Field Data Types|
| image_uuid | string |  | Image UUID | Image UUID|
| layout_image_uuid | string |  | Layout Image UUID | Layout Image UUID|
| language | string |  | Language | Language used for transcribing fields|
| image_source | string |  | Image source (IDP or empty) | Image source to be used for fetching the image specified by image_uuid|



## EXPORT_UIPATH

name: UiPath Notifier

uuid: 1f5dee40-1e18-492a-b41b-da223df338ef

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| url | string | N/A | URL | Base URL of the uipath instance|
| organization_unit_id | string | null | Organization unit id | Organization unit id|
| tenant | string | N/A | Tenant | Tenant|
| username | string | N/A | Username | Username|
| password | Password | N/A | Password | Password|
| queue | string | N/A | Queue | Queue|
| payload_uuid | string | null | Payload UUID | Payload to be sent in notification|



## FULL_PAGE_OICR

name: FULL PAGE OICR transcriber

uuid: c78a48eb-53dc-4583-9139-a1150758d8b7

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| fields | array | [] | Fields | Fields|
| image_uuid | string |  | Image UUID | Image UUID|
| language | string |  | Language | Language used for transcribing fields|
| image_source | string |  | Image source (IDP or empty) | Image source to be used for fetching the image specified by image_uuid|



## ANALYTICS_TRIGGER

name: Analytics Listener

uuid: 6e187385-04b8-4693-8af0-0b36ef609634

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| folder | path | N/A | Folder to scan for events files | N/A|
| poll_interval | int | 10 | Poll interval in seconds | N/A|



## APPLY_OICR_THRESHOLDS_2

name: Apply Oicr Thresholds

uuid: 3accd5ec-7fae-4cfc-9012-78c45cac02f3

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| $alias_name | string | CUSTOM_CODE | Aliased Block | Aliased Block|
| $partial_input_parameters | object | {'code': "from enum import Enum\nfrom typing import Dict, List, Optional\n\nfrom blocks.base_python_block import Block, WFEngineTask, WFEngineTaskResult\nfrom blocks.types import BaseModel, BlockInputs\n\n\nclass SupervisionMode(Enum):\n    Default = 0\n    Consensus = 1\n    Autotranscribe = 2\n    SupervisionAlways = 3\n\n\nclass ConfidenceResult(str, Enum):\n    NONE = 'none'\n    SURE = 'sure'\n    NOT_SURE = 'not_sure'\n\n\nclass Entry(BaseModel):\n    identifier: str\n    model_type: str\n    type: str  # 'field' or 'cell'; should change name but that requires lots of workflow changes\n    transcription_sv_mode: SupervisionMode\n    transcription: Optional[str]\n    bounding_box: Optional[List[float]]\n    confidence: Optional[float]\n    ft_confidence: Optional[float] = None\n    ft_result: ConfidenceResult = ConfidenceResult.NONE\n    boosted_confidence: Optional[float] = None\n\n\nclass Thresholds(BaseModel):\n    confidence_threshold: float\n    acceptable_threshold: float\n\n\nclass CustomCodeBlockProxyInputs(BlockInputs):\n    require_transcriptions: bool\n    thresholds: Dict[str, Thresholds]\n    entries: List[Entry]\n    ignored_meta_types: Optional[List[str]] = None\n\n\nclass ThresholdError(Enum):\n    ConsensusNeeded = 'consensus_needed'\n    SupervisionRequired = 'supervision_required'\n    TranscriptionRequired = 'transcription_required'\n    LowConfidence = 'low_confidence'\n    NotSure = 'not_sure'\n\n\nclass MachineConfidenceLevel(Enum):\n    Confident = 1\n    NotSure = 2\n    Illegible = 3\n\n\ndef process_task(\n    proxy: Block, task: WFEngineTask[CustomCodeBlockProxyInputs]\n) -> WFEngineTaskResult:\n    ignored_meta_types = set(task.inputData.ignored_meta_types or [])\n    result = []\n\n    for entry in task.inputData.entries:\n        should_supervise = False if entry.model_type == 'barcode' else None\n\n        not_present = entry.bounding_box is None\n        is_ignored = entry.model_type in ignored_meta_types\n\n        if not_present or is_ignored:\n            processed = _create_processed_entry(\n                entry, error=None, should_supervise=should_supervise\n            )\n        elif entry.transcription_sv_mode == SupervisionMode.Consensus:\n            processed = _create_processed_entry(\n                entry, ThresholdError.ConsensusNeeded, should_supervise=should_supervise\n            )\n        elif entry.transcription_sv_mode == SupervisionMode.SupervisionAlways:\n            processed = _create_processed_entry(\n                entry, ThresholdError.SupervisionRequired, should_supervise=should_supervise\n            )\n        elif entry.transcription_sv_mode == SupervisionMode.Autotranscribe:\n            error = _get_autotranscribe_mode_error(\n                entry, task.inputData.require_transcriptions, task.inputData.thresholds\n            )\n            processed = _create_processed_entry(entry, error, should_supervise=False)\n        else:\n            error = _get_default_mode_error(\n                entry, task.inputData.require_transcriptions, task.inputData.thresholds\n            )\n            processed = _create_processed_entry(entry, error, should_supervise=should_supervise)\n\n        result.append(processed)\n\n    return {'entries': result}\n\n\ndef _create_processed_entry(\n    entry: Entry, error: Optional[ThresholdError], should_supervise: Optional[bool] = None\n) -> dict:\n    if should_supervise is None:\n        should_supervise = error is not None\n\n    return {\n        'identifier': entry.identifier,\n        'should_supervise': should_supervise,\n        'threshold_error': error.value if error else None,\n    }\n\n\ndef _get_autotranscribe_mode_error(\n    entry: Entry, require_transcriptions: bool, thresholds_map: Dict[str, Thresholds]\n) -> Optional[ThresholdError]:\n    if require_transcriptions and not entry.transcription and entry.type != 'cell':\n        return ThresholdError.TranscriptionRequired\n\n    confidence_level = _get_confidence_level(entry, thresholds_map)\n\n    if confidence_level == MachineConfidenceLevel.Illegible:\n        return ThresholdError.LowConfidence\n\n    return None\n\n\ndef _get_default_mode_error(\n    entry: Entry, require_transcriptions: bool, thresholds_map: Dict[str, Thresholds]\n) -> Optional[ThresholdError]:\n    # Blank cells are handled separately by Manual Transcription\n    if require_transcriptions and not entry.transcription and entry.type != 'cell':\n        return ThresholdError.TranscriptionRequired\n\n    confidence_level = _get_confidence_level(entry, thresholds_map)\n\n    if confidence_level == MachineConfidenceLevel.Confident:\n        return None\n\n    if confidence_level == MachineConfidenceLevel.Illegible:\n        return ThresholdError.LowConfidence\n\n    return ThresholdError.NotSure\n\n\ndef _get_confidence_level(\n    entry: Entry, thresholds_map: Dict[str, Thresholds]\n) -> MachineConfidenceLevel:\n    confidence = _get_machine_confidence(entry)\n\n    if confidence is None:\n        return MachineConfidenceLevel.Illegible\n\n    confidence_result = _get_confidence_result(entry, confidence, thresholds_map)\n    if confidence_result == ConfidenceResult.SURE:\n        return MachineConfidenceLevel.Confident\n\n    acceptable_threshold = _get_acceptable_threshold(entry, thresholds_map)\n    if confidence >= acceptable_threshold:\n        return MachineConfidenceLevel.NotSure\n\n    return MachineConfidenceLevel.Illegible\n\n\ndef _should_apply_ft_confidence(entry: Entry) -> bool:\n    return entry.ft_result != ConfidenceResult.NONE\n\n\ndef _get_machine_confidence(entry: Entry) -> Optional[float]:\n    if _should_apply_ft_confidence(entry):\n        return entry.ft_confidence\n\n    if entry.boosted_confidence is not None:\n        return entry.boosted_confidence\n\n    return entry.confidence\n\n\ndef _get_confidence_result(\n    entry: Entry, confidence: float, thresholds_map: Dict[str, Thresholds]\n) -> ConfidenceResult:\n    if _should_apply_ft_confidence(entry):\n        return entry.ft_result\n\n    thresholds = thresholds_map[entry.model_type]\n    return (\n        ConfidenceResult.SURE\n        if confidence >= thresholds.confidence_threshold\n        else ConfidenceResult.NOT_SURE\n    )\n\n\ndef _get_acceptable_threshold(entry: Entry, thresholds_map: Dict[str, Thresholds]) -> float:\n    thresholds = thresholds_map[entry.model_type]\n\n    return thresholds.acceptable_threshold\n"} | Partial Input Parameters | Pass these partial input parameters to the aliased block|
| require_transcriptions | boolean | True | Require Transcriptions | Specifies whether error should be raised for entries without transcriptions|
| thresholds | object | {} | Thresholds | Confidence Thresholds|
| entries | array | [] | Entries | Entries to which the thresholds will be applied|



## UNIVERSAL_FOLDER_TRIGGER

name: Universal Folder Listener

uuid: d0af79f0-4084-4a76-aa4d-cdf734bb0157

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| folder | string |  | Folder to scan for submissions | Enter the path relative to the base folder. Leave blank to monitor the base folder|
| file_extensions | array | [] | File extensions | Types of file extensions for which to monitor|
| other_file_extensions | string | N/A | Other file extensions | Comma separated list of file extensions for which to monitor (e.g. 'png, jpg, pdf')|
| has_meta | boolean | False | Include submission level parameters | Select this to ingest JSON files along with document files and submission folders. These JSON files can contain information such as metadata, cases and external_id. These JSON file names should match the related files or folders (e.g., XXX.jpg.json for XXX.jpg)|
| poll_interval | integer | 10 | Polling interval (in seconds) | How often the Folder Listener will check the base folder for submissions|
| warmup_interval | integer | 15 | Warm-up interval (in seconds) | How long the Folder Listener will wait to process the document after it was last modified|
| folder_cleanup_delay | number | 24 | Empty folder cleanup delay (in hours) | How often the Folder Listener will remove empty folders from the base folder|
| api_params | object | {} | API Parameters | N/A|



## SEGMENTATION

name: Segmentation

uuid: cca2261b-a41b-4d85-b79d-afaadba76bc0

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| image_uuid | string |  | Image UUID | Image UUID|
| rotation_correction_enabled | boolean | True | Rotation Correction Enabled on the Input Image | Rotation Correction Enabled on the Input Image|
| image_source | string |  | Image source (IDP or empty) | Image source to be used for fetching the image specified by image_uuid|



## BOX_FOLDER_TRIGGER

name: Box Folder Listener

uuid: 5ba19375-d8c2-4876-b666-a08e427d186f

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| source_folder_id | integer | N/A | Folder to scan for submissions | Use the Box Folder ID found in the URL|
| target_folder_id | integer | N/A | Folder to move completed files | Use the Box Folder ID found in the URL|
| file_extensions | array | [] | File extensions | Types of file extensions for which to monitor|
| custom_file_extensions | string | N/A | Other file extension types | Comma separated list of file extensions for which to monitor (e.g. 'png, jpg, pdf')|
| poll_interval | integer | 10 | Polling interval (in seconds) | How often the connector will check the base folder for submissions|
| warmup_interval | integer | 15 | Warm-up interval (in seconds) | How long the connector will wait to process the document after it was last modified|
| public_key_id | string | N/A | Public-Key ID | ID of the Public-key used for authentication with Box|
| private_key | Password | N/A | Private-Key | Private key used for authentication with Box|
| passphrase | Password | N/A | Passphrase | Passphrase used for authentication with Box|
| client_id | string | N/A | Client ID | Client Id used for authentication with Box|
| client_secret | Password | N/A | Client Secret | Client Secret used for authentication with Box|
| enterprise_id | string | N/A | Enterprise ID | Enterprise Id used for authentication with Box|
| api_params | object | {} | API Parameters | N/A|



## EXTERNAL_JOB_PREPARE

name: External Job Prepare

uuid: aca51f02-598b-44aa-80a5-e901fd4f469f

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| $alias_name | string | CUSTOM_CODE | Aliased Block | Aliased Block|
| $partial_input_parameters | object | {'code': "import json\n\nfrom blocks.api import EXTERNAL_JOBS_LIST_URL\nfrom blocks.base_python_block import Block, WFEngineTask, WFEngineTaskResult\nfrom blocks.types import BlockInputs\n\n\nclass CustomCodeBlockProxyInputs(BlockInputs):\n    wait_task_ref_name: str\n\n\ndef process_task(\n    proxy: Block, task: WFEngineTask[CustomCodeBlockProxyInputs]\n) -> WFEngineTaskResult:\n    workflow_instance_id: str = task.workflowInstanceId\n    wait_task_ref_name: str = task.inputData.wait_task_ref_name\n\n    proxy.log('Received input: wf_id={} wait_task_ref={}', workflow_instance_id, wait_task_ref_name)\n\n    # Create a new `ExternalJob` instance\n    create_payload = {\n        'workflow_run_uuid': workflow_instance_id,\n        'wait_task_ref_name': wait_task_ref_name,\n    }\n    resp = proxy.sdm_post(EXTERNAL_JOBS_LIST_URL, json=create_payload)\n\n    output_data = {'external_job': resp.json()}\n    proxy.log('Output: {}', json.dumps(output_data))\n\n    return output_data\n"} | Partial Input Parameters | Pass these partial input parameters to the aliased block|
| wait_task_ref_name | string |  | Wait Task Ref Name | Wait Task Ref Name|



## ANALYTICS_TRANSMIT

name: Analytics transmit

uuid: 18c1638e-9260-4472-90b7-289dd2257c95

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| filebeat_timeout_seconds | integer | null | Timeout for executing filebeat subprocess not individual network calls | N/A|
| logstash_host | string | null | Logstash Host | N/A|
| telemetry_ca | string | null | Telemetry CA | N/A|
| telemetry_cert | string | null | Telemetry cert | N/A|
| telemetry_key | string | null | Telemetry key | N/A|
| start | DateTime | null | Start report date | Start datetime|



## USAGE_REPORT

name: Usage report

uuid: 3d9bb15a-9b0a-463e-8f78-4fccfb82cf69

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| filebeat_timeout_seconds | integer | null | Filebeat Timeout Seconds | N/A|
| logstash_host | string | null | Logstash Host | N/A|
| telemetry_analytics_enabled | boolean | True | Telemetry Analytics Enabled | N/A|
| telemetry_ca | string | null | Telemetry CA | N/A|
| telemetry_cert | string | null | Telemetry cert | N/A|
| telemetry_key | string | null | Telemetry key | N/A|
| start | DateTime | null | Start report date | Start datetime|



## SOAP_REQ

name: SOAP API Request

uuid: 2c6aa317-2a06-44dd-af0c-08d8f4050129

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| endpoint | string | N/A | Endpoint URL | Absolute URL including schema to HTTP endpoint for this request.|
| method | string |  | Method | SOAP Method to invoke|
| body_namespace | string | null | Body Namespace | SOAP request body namespace URI|
| headers_namespace | string | null | Headers Namespace | SOAP request headers namespace URI|
| headers | object | N/A | SOAP Headers | SOAP Headers|
| params | object | null | SOAP parameters | Key-value pair used as query parameters in the request to be inserted as soap body|



## HTTP_DOWNLOADER

name: HTTP Downloader

uuid: c7e1f048-f817-43fc-900b-6eabfa3dfb9a

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| headers | object | {} | URL Headers | N/A|
| url | string |  | URL | URL|



## BOX_NOTIFIER

name: Box Notifier

uuid: d1b27dfe-799d-416f-87fe-a2810fc7c658

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| public_key_id | string | N/A | Public-Key ID | ID of the Public-key used for authentication with Box|
| private_key | Password | N/A | Private-Key | Private key used for authentication with Box|
| passphrase | Password | N/A | Passphrase | Passphrase used for authentication with Box|
| client_id | string | N/A | Client ID | Client Id used for authentication with Box|
| client_secret | Password | N/A | Client Secret | Client Secret used for authentication with Box|
| enterprise_id | string | N/A | Enterprise ID | Enterprise Id used for authentication with Box|
| template_key | string |  | Box Metadata Template Key | Enter the key of the Box Metadata template that you would like to map the Hyperscience metadata to.|
| static_output_fields_to_map | array | [] | Static Metadata Fields | Specify the Hyperscience fields you want to store in Box metadata.|
| submission_id | string |  | Key for Mapping Submission ID | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| document_id | string |  | Key for Mapping Document ID | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| submission_state | string |  | Key for Mapping Submission State | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| document_state | string |  | Key for Mapping Document State | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| submission_exceptions | string |  | Key for Mapping Submission Exceptions | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| document_exceptions | string |  | Key for Mapping Document Exceptions | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| document_layout_uuid | string |  | Key for Mapping Document Layout Uuid | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| document_layout_name | string |  | Key for Mapping Document Layout Name | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| start_time | string |  | Key for Mapping Start Time | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| complete_time | string |  | Key for Mapping Complete Time | Specify a Box metadata field key from your chosen Box template.  The Hyperscience field will be stored in this specified field.|
| document_fields_template_mappings | json | {} | JSON for Additional Metadata Fields | Specify additional metadata fields using their key value. Please consult Box Integration setup manual for JSON template and instructions.|
| payload_uuid | string | null | Payload | Payload to be sent in notification|



## CRON_TRIGGER

name: Cron Listener

uuid: 798a30f3-06d7-49dd-8156-fe04b6cab2f2

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| cron_spec | string | */5 * * * * | Cron specification | N/A|
| time_zone | string | US/Eastern | Time Zone | N/A|
| api_params | object | {} | API Parameters | N/A|



## TABLE_LOCATOR

name: Table Locator

uuid: 25ac1fa0-90d7-4423-a22a-a52a7b9bc0e3

Inputs:

| name | type | default value | title | description |
| ---  | ---  | ---           | ---   | ---         |
| ml_model | object | {'model_id': '', 'model_type': ''} | ML model reference | ML Model reference|
| model_info_url | string |  | ML Model Info URL | URL to use for ML model info retrieval|
| target_accuracy | number |  | Target accuracy | Target machine accuracy|
| pages | array | [] | Pages | List of pages|


